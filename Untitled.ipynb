{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32513677, 0.48331305],\n",
       "       [0.18387203, 0.3704959 ],\n",
       "       [0.63578012, 0.69134266]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.random((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a ():\n",
    "    return tuple(map(lambda x : x-1,[3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_cache.h5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../work/data/cache\" \n",
    "a = !ls $path\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#cached  = open(os.path.join(path,a[0]),\"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "h5 = pd.HDFStore(os.path.join(path,a[0]),\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiron-0.4.zip       chiron_deneme.ipynb  \u001b[34mrefer_paper\u001b[m\u001b[m/\r\n",
      "\u001b[34mChiron2\u001b[m\u001b[m/             chironpaper.pdf      \u001b[34msup_con\u001b[m\u001b[m/\r\n",
      "Untitled.ipynb       command_for_nvidia   toy_data.pk\r\n",
      "all_data.pk          \u001b[34mmy_chiron\u001b[m\u001b[m/           \u001b[34mwork\u001b[m\u001b[m/\r\n",
      "\u001b[34mchiron\u001b[m\u001b[m/              my_chiron_eval.py    x_data.pk\r\n",
      "chiron notes         my_reader.py         y_data.pk\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = tables.open_file(os.path.join(path,a[0]), driver=\"H5FD_CORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = tables.open_file(os.path.join(path,a[0]), mode=\"r\", title=\"Test file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "import numpy as np\n",
    "h5file = tables.open_file(os.path.join(path,'train_cache.h5'), driver=\"H5FD_CORE\")\n",
    "root = h5file.root\n",
    "#a = root._f_get_child(\"label_raw\")._v_nchildren\n",
    "Y_ctc = root._f_get_child('Y_ctc')\n",
    "Y_seg = root._f_get_child('Y_seg')\n",
    "X_data = root._f_get_child('X_data')\n",
    "Y_vec = root._f_get_child('Y_vec')\n",
    "seq_len = root._f_get_child('seq_len')\n",
    "def segmentstonucleotides(segments,y_vec):\n",
    "    nucleotides = [y_vec[0]]\n",
    "    #print(segments)\n",
    "    #print(y_vec)\n",
    "    segment = segments[0]\n",
    "    i = 1\n",
    "    ind = segment\n",
    "    while(segment!=0):\n",
    "        if y_vec[ind]!=-1:\n",
    "            nucleotides.append(y_vec[ind])\n",
    "        segment = segments[i]\n",
    "        ind += segment\n",
    "        i+=1\n",
    "    return nucleotides\n",
    "avail_data = {}\n",
    "for key in range(len(X_data)):\n",
    "    segs = np.array(Y_seg[str(key)])\n",
    "    #print(key)\n",
    "    avail_data[key] = {}\n",
    "    avail_data[key][\"x_data\"] = X_data[int(key)]\n",
    "    avail_data[key][\"y_vec\"]  = Y_vec[int(key)]\n",
    "    avail_data[key][\"segments\"] = segs\n",
    "    avail_data[key][\"nucleotides\"] = segmentstonucleotides(segs,Y_vec[int(key)])\n",
    "avail_file = open(\"all_data.pk\",\"wb\")\n",
    "pickle.dump(avail_data,avail_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentstonucleotides(segments,y_vec):\n",
    "    nucleotides = [y_vec[0]]\n",
    "    #print(segments)\n",
    "    #print(y_vec)\n",
    "    segment = segments[0]\n",
    "    i = 1\n",
    "    ind = segment\n",
    "    while(segment!=0):\n",
    "        if y_vec[ind]!=-1:\n",
    "            nucleotides.append(y_vec[ind])\n",
    "        segment = segments[i]\n",
    "        ind += segment\n",
    "        i+=1\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_data = {}\n",
    "for key in range(len(X_data)):\n",
    "    segs = np.array(Y_seg[str(key)])\n",
    "    #print(key)\n",
    "    avail_data[key] = {}\n",
    "    avail_data[key][\"x_data\"] = X_data[int(key)]\n",
    "    avail_data[key][\"y_vec\"]  = Y_vec[int(key)]\n",
    "    avail_data[key][\"segments\"] = segs\n",
    "    avail_data[key][\"nucleotides\"] = segmentstonucleotides(segs,Y_vec[int(key)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_non_zeros = lambda l : len(list(filter(lambda x : x !=0 ,l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for key in avail_data:\n",
    "    nucs = avail_data[key][\"nucleotides\"]\n",
    "    segs = avail_data[key][\"segments\"]\n",
    "    if -1 in nucs:\n",
    "        c+=1\n",
    "    elif count_non_zeros(segs)!=len(nucs):\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_file = open(\"all_data.pk\",\"wb\")\n",
    "pickle.dump(avail_data,avail_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "segmented_data = pickle.load(open(\"all_data.pk\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pickle\n",
    "random.seed(0)\n",
    "def toy_pickle(dic,size,outname):\n",
    "    new_dic = {}\n",
    "    keys = list(dic.keys())\n",
    "    random.shuffle(keys)\n",
    "    for key in keys[:size]:\n",
    "        new_dic[key] = dic[key]\n",
    "    of = open(outname,\"wb\")\n",
    "    pickle.dump(new_dic,of)\n",
    "    of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = segmented_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_pickle(segmented_data,1000,\"toy_data.pk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "a = numpy.array([1,2,3])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(segmented_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '1', '2', '4']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
       "        3,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        2,  2,  2,  2,  2,  2,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  4,  4,  4,  4,\n",
       "        2,  2,  2,  2,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  1,  1,  1,\n",
       "        1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=int32)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vecs[266807]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [x for x in y_ctc._f_get_child(\"shape\")]\n",
    "value = [x for x in y_ctc._f_get_child(\"value\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = y_ctc._f_get_child(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unutmamak icin not aliyoruuum:\n",
    "\n",
    "Y_seg raw signalin segmentlere ayrilmis hali. Icinde bir nucleotide gelen sinyallerin uzunluklari var. 19 5 3 mesela 3 tane nucleotid oldugunu gosteriyor belki ayni nucleotid type olabilir ama farkli nucleotidler bunlar. Bu datayi ve y_vec datasini kullanarak belli bir 300luk sinyalin her verisi icin hangi nucleotidi okudugumuzu bulabiliriz ancak 151 uzunlugunda bir tane de var mesela bu tam olarak ne demek?\n",
    "\n",
    "y_vecs labellarin 300 uzunluga map edilmis hali gibi dusunulebilir. ama bunun da sonunun neden -1 oldugunu tam anlamadim.\n",
    "\n",
    "x_vecs 300 uzunlugundaki sinyalleri gosteriyor.\n",
    "\n",
    "Yukaridaki uc dokuman ayni sekilde indexlenmis 0,1,2, ....\n",
    "\n",
    "seq_len bize y_vec in uzunlugunu veriyor. Bu indexten sonrasi -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_arr = []\n",
    "for x in x_data:\n",
    "    x_arr.append(x)\n",
    "x_train = open(\"x_data.pk\",\"wb\")\n",
    "pickle.dump(x_arr,x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = []\n",
    "for y in y_vecs:\n",
    "    y_arr.append(y)\n",
    "y_train = open(\"y_data.pk\",\"wb\")\n",
    "pickle.dump(y_arr,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = pickle.load(open(\"x_data.pk\",\"rb\"))\n",
    "y_tr = pickle.load(open(\"y_data.pk\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  3,  3,  3,  3,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  1,  1,  1,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  2,\n",
       "        2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  4,  4,  4,  4,  4,  2,\n",
       "        2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  3,  3,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2, -1, -1, -1], dtype=int32)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = [1,2,3,2,2,3,1]\n",
    "seq2 = [1,2,3,2,3,3]\n",
    "\n",
    "def edit_distance(seq1,seq2):\n",
    "    edits = [[0 for i in range(len(seq2)+1)]for j in range(len(seq1)+1)]\n",
    "    for i in range(0,len(seq1)):\n",
    "        for j in range(0,len(seq2)):\n",
    "            if seq1[i]==seq2[j]:\n",
    "                edits[i+1][j+1] = min(edits[i][j+1]+1,edits[i][j],edits[i+1][j]+1)\n",
    "            else:\n",
    "                edits[i+1][j+1] = min(edits[i][j+1],edits[i][j],edits[i+1][j])+1\n",
    "    return edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,5,5]\n",
    "b = [1,2,3,4,5]\n",
    "edits = edit_distance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edits[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predict(predict_read):\n",
    "    return list(map(lambda x : x+1,predict_read))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_predict([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE FAST5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "import os\n",
    "path = \"/Users/ardaakdemir/Desktop/nanopore/Chiron2/chiron/example_data\"\n",
    "name = \"read1.fast5\"\n",
    "h5file = tables.open_file(os.path.join(path,name), driver=\"H5FD_CORE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast5 formati minion ile okunan segmented veri oluyor. Her raw signali vermek yerine mean std signal length veriyor ve starting index. Bunlarla daha sonra her segment labellaniyor falan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/ (RootGroup) ''\n",
       "  children := ['Analyses' (Group), 'Raw' (Group), 'UniqueGlobalKey' (Group)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = h5file.root\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = root._f_get_child('Analyses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Analyses (Group) ''\n",
       "  children := ['EventDetection_000' (Group)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = analyses[\"EventDetection_000\"][\"Reads\"][\"Read_104\"][\"Events\"]\n",
    "leng = 0\n",
    "for x in analysis :\n",
    "    leng+= x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Analyses/EventDetection_000/Reads/Read_104/Events (Table(5524,), zlib(4)) ''\n",
       "  description := {\n",
       "  \"mean\": Float64Col(shape=(), dflt=0.0, pos=0),\n",
       "  \"stdv\": Float64Col(shape=(), dflt=0.0, pos=1),\n",
       "  \"start\": Int64Col(shape=(), dflt=0, pos=2),\n",
       "  \"length\": Int64Col(shape=(), dflt=0, pos=3)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (346,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = root._f_get_child('Raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([487, 421, 433, 438, 452, 440, 440, 452, 454, 435], dtype=int16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = raw['Reads'][\"Read_104\"]['Signal']\n",
    "signal[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
